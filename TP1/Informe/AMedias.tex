\section{Problema 2: A medias}

\subsection{Descripción de la problemática}
En este problema se nos pide calcular todas las medianas parciales, que se obtienen al tomar subconjuntos del original de la siguiente manera:
Suponiendo que tengo el siguiente conjunto $\{2,8,5,3,10\}$, tomamos los subconjuntos
\begin{center}
	$\{2\}$ $\{2,8\}$ $\{2,8,5\}$ $\{2,8,5,3\}$ $\{2,8,5,3,10\}$
\end{center}
Luego- entendiendo la mediana como el valor en la posición central o el promedio entre los dos valores en las posiciones centrales (en el caso que la cantidad de elementos sea par) de un conjunto de datos ordenados - la calculamos para cada uno de esos subconjuntos. De esta manera, con el algoritmo que analizaremos a continuación, podemos obtener el siguiente conjunto de medianas $\{2,5,5,4,5\}$ que es solución al problema y que cumple que el $i$-ésimo, con $i = \{0 $..$ 4\}$, representa la parte entera de la mediana de los primeros $i$ números de la entrada.

\subsection{Resolución propuesta y justificación}

La solución que proponemos utiliza dos heaps (uno que ordena los elementos de menor a mayor -min heap- y el otro de mayor a menor -max heap-) para obtener de forma rápida los elementos que se encuentran en la mitad del conjunto ordenado. Para lograr esto, el algoritmo almacena los elementos mas grandes en el min heap y los mas chicos en el max heap, decidiendo si es mas chico o mas grande al compararlo con la mediana del subconjunto anterior.\\

El pseudocódigo que se muestra a continuación representa nuestro algoritmo y en el mismo se utilizan las variables $heap1$ y $heap2$ solamente para mostrar que estamos comparando los dos heaps y que no importa diferenciar cual es el max y cual es el min heap.\\

Pseudocódigo:
\begin{algorithmic}
	\STATE $mediana =$ mediana actual (inicializada en cero)
	\FOR{Cantidad de elementos en el conjunto}
		\IF{Valor del elemento actual $\geq mediana$}
			\STATE Insertar el valor en el min heap
		\ELSE
			\STATE Insertar el valor en el max heap
		\ENDIF
		%balancear heaps
		\IF{La diferencia absoluta entre los tamaños de los dos heaps $>$ 1}
			\STATE Pasar la cabeza del heap mas grande al otro heap
		\ENDIF

		%calcular mediana
		\IF{Tamaño del $heap1 =$ tamaño del $heap2$}
			\STATE $mediana = $ el promedio entre las cabezas de los heaps
		\ELSE
			\STATE $mediana = $ la cabeza del heap mas grande
		\ENDIF
		\STATE Devolver $mediana$
	\ENDFOR
\end{algorithmic}


Los heaps se encargan de mantener ordenadas las dos mitades del conjunto, pero como no se sabe de antemano contra que valor comparar para ubicar los elementos en el heap correcto, los mismos se pueden debalancear, generando que los elementos del medio no se encuentren en las cabezas. Por este motivo si llega a ocurrir ese caso, balanceamos los heaps pasando la cabeza del heap mas grande al otro.\\

Luego calcular la mediana simplemente implica decidir si el subconjunto actual tiene cantidad par o impar de elementos y en función de eso, calcular el promedio de las dos cabezas o tomar la cabeza del heap mas grande.

Por el invariante del ciclo \emph{for}: \texttt{\{$i >= 0 \land i <$ cantidad de elementos del conjunto $\land\ mediana =$ mediana de los primero $i$ números\}}, podemos asegurar que el ciclo termina, ya que se cumple antes y después de cada iteración del ciclo y al darse la condición de terminación (\texttt{$i >=$ cantidad de elementos del conjunto}), efectivamente termina.\\

Luego por la documentación de \emph{Priority Queue} sabemos que los heaps van a mantener los elementos ordenado en todo momento, dándonos fácil acceso al mínimo y el máximo. Al rebalancear los heaps nos aseguramos de que siempre se cumpla que la diferencia absoluta entre los tamaños de los heaps sea menor igual a uno, lo que causa que los heaps tengan la mitad o la mitad mas uno de los elementos del subconjunto actual.\\

Teniendo en cuenta que vale lo anterior y por estar ordenados de forma ascendente el que contiene los elementos más pequeños y de forma descendente el otro, se cumple que las cabezas siempre representan a los elementos centrales del subconjunto actual con $j$ elementos, o sea, los valores en las posiciones $j/2 \land (j/2)+1$. Por lo que para calcular la mediana podemos obtener los tamaños de los heaps y decidir si hay que calcular el promedio o devolver la cabeza del mas grande. De esta manera el algoritmo cumple con la definición de mediana para cada subconjunto incremental.

\subsection{Análisis de la complejidad}
Nuestra solución tiene una complejidad temporal de $\mathcal{O}(n\log{}n)$ siendo $n$ la cantidad de elementos del conjunto. \\

El algoritmo está contenido en un \emph{for} que recorre una sola vez cada elemento del conjunto, con lo cual la ejecución de ese ciclo tiene una complejidad de $\mathcal{O}(n)$. Luego se utilizan los métodos de la clase \emph{Heap} que utiliza como base a la clase \emph{Priority Queue} que está incluida en \emph{java.util}. Las complejidades de todos los métodos de \emph{Priority Queue} que se mencionan a continuación, están especificadas en la documentación de java\footnote{http://docs.oracle.com/javase/7/docs/api/java/util/PriorityQueue.html}. El algoritmo ejecuta los métodos de \emph{Heap} de la siguiente manera:

\begin{itemize}
	\item Insertar elemento en heap: Es $\mathcal{O}(1)$ elegir en que heap se va a insertar el elemento mas $\mathcal{O}(\log{}n)$ insertar en la cola de prioridad con \emph{PriorityQueue.add()}.\\ Notar que el elemento nunca se inserta en los dos heaps, por lo tanto la complejidad queda\\ $\mathcal{O}(1) + \mathcal{O}(\log{}n) = \mathcal{O}(\log{}n)$.
	\item Balancear heaps: Hace comparaciones y asignaciones en $\mathcal{O}(1)$, luego llama a \emph{PriorityQueue.poll()} que obtiene y remueve la cabeza del heap en $\mathcal{O}(\log{}n)$ y por último inserta la cabeza en el otro heap con \emph{PriorityQueue.add()} también en $\mathcal{O}(\log{}n)$.\\ Quedando una complejidad de $k * \mathcal{O}(1) + 2 * \mathcal{O}(\log{}n) = \mathcal{O}(\log{}n)$ con $k$ una constante.
	\item Calcular mediana: Hace operaciones aritméticas, asignaciones y comparaciones en $\mathcal{O}(1)$, obtiene los tamaños de los heaps con \emph{PriorityQueue.size()} también en $\mathcal{O}(1)$ y obtiene la cabeza de uno o de los dos heaps, lo cual no hace diferencia ya que la complejidad de \emph{PriorityQueue.peek()} es $\mathcal{O}(1)$.\\ En este paso nos queda una complejidad de $k * \mathcal{O}(1) = \mathcal{O}(1)$ con $k$ una constante.
\end{itemize}

\noindent Por lo tanto, siguiendo el análisis de complejidad, nos termina quedando:
\begin{center}
	$\mathcal{O}(n) * (\mathcal{O}(\log{}n) + \mathcal{O}(\log{}n) + \mathcal{O}(1)) = \mathcal{O}(n\log{}n)$
\end{center}
Lo cual condice la afirmación que hicimos al principio de la subsección.

\newpage
\subsection{Código fuente}
A continuación se incluyen las partes más relevantes del código.\\
El loop principal que se encuentra en la clase \emph{Main.java}:
\lstinputlisting[name=AMedias, numbers=left, frame=lines, firstline=30, lastline=47]{../src/ej2/src/Main.java}
Los métodos que manipulan los heaps que se encuentran en la clase \emph{Heap.java}
\lstinputlisting[name=Heaps, numbers=left, frame=lines, firstline=7, lastline=18]{../src/ej2/src/Heap.java}
\lstinputlisting[name=Heaps, numbers=left, frame=lines, firstline=20, lastline=38]{../src/ej2/src/Heap.java}
\lstinputlisting[name=Heaps, numbers=left, frame=lines, firstline=40, lastline=52]{../src/ej2/src/Heap.java}

\subsection{Experimentación}
Para analizar la performance del algoritmo creamos dos scripts: uno que se encarga de generar casos de test pseudoaletorios\footnote{genTest.sh}, el cual genera archivos con instancias del problema incrementando el $n$ con un cierto espaciado; El otro script\footnote{testPerformance.sh} se encarga de correr el programa una cierta cantidad de veces para cada instancia generada por el primer script, luego descarta los outliers y calcula el tiempo promedio entre todas las corridas. Estos promedios se guardan en el archivo \emph{resultados.out}.

\subsubsection{Constrastación Empírica de la complejidad}
A continuación presentamos dos gráficos que muestran el comportamiento en la práctica del algoritmo. Para obtener estos resultados utilizamos 301 tests cada uno conteniendo una instancia del problema en las que el $n$ varía entre 1 y 3001, saltando de a 10 números y los valores de cada instancia se generaron pseudoaleatoriamente con un rango entre 1 y 10000. Luego, cada una de estas instancias fue ejecutada 100 veces.


\begin{figure}[h!]
	\centering
 	\includegraphics[scale=0.8]{imagenes/ej2/tiempos.png}
	\caption{Medición de tiempo promedio entre 100 corridas}
	\label{tiemposprom}
 \end{figure}

 Al mirar el gráfico de la figura \ref{tiemposprom} no queda muy claro que la cota de complejidad propuesta sea correcta. Por lo que decidimos linealizar los resultados, dividiéndolos por $k * \log{n}$ con $n$ tamaño del input y $k$ una constante. Como se esperaba, el gráfico de la figura \ref{tiempolineal} se asemeja bastante a una recta. Con lo cual parecería que el algoritmo cumple con la cota de complejidad teórica que analizamos anteriormente.

 \begin{figure}[h!]
 	\centering
 	\includegraphics[scale=0.8]{imagenes/ej2/linealizacion.png}
	\caption{Tiempo promedio dividido por el logaritmo del tamaño del input}
	\label{tiempolineal}
 \end{figure}

Por último, tomamos los tiempos promedio y los dividimos por la cota teórica para poder observar si los resultados tienden a una constante.

\begin{figure}[h!]
	\centering
 	\includegraphics[scale=0.8]{imagenes/ej2/cota.png}
	\caption{Tiempo promedio dividido por la cota de complejidad}
	\label{cotalog}
 \end{figure}

La figura \ref{cotalog} muestra este análisis en el que efectivamente los resultados parecen tender a una constante. De esta forma concluimos que el algoritmo cumple con la cota de complejidad propuesta. 